# **Signboard Translation from Vernacular Languages** 🌐✨  

![image](https://github.com/user-attachments/assets/06b70652-772e-4e2d-afec-517e6e172ee7)


### **Breaking Language Barriers with AI**  

Imagine navigating through unfamiliar streets where signboards speak a language you don’t understand. 🚏 That’s where **Signboard Translation from Vernacular Languages** steps in, combining cutting-edge technology to break linguistic barriers and make navigation seamless for everyone.  

## **🌟 What It’s All About**  
This project leverages the power of **Machine Learning** 🤖, **Computer Vision** 🖼️, and **Natural Language Processing (NLP)** 🌍 to translate text from signboards written in regional or vernacular languages into a desired language, such as English. It’s an intelligent system that doesn’t just read signboards – it **understands** them.  


## **🔧 The Tech Behind the Magic**  

1. **🔍 Text Detection with YOLOv5**  
   - Using **YOLOv5**, the project precisely detects text regions in images, even in complex or noisy environments.  
   - Ensures fast and accurate localization, laying the groundwork for the translation pipeline.  

2. **📜 Text Extraction with OCR**  
   - Text from the detected regions is extracted using advanced **Optical Character Recognition (OCR)** tools.  
   - Handles clear and faded text with remarkable precision, making it ideal for real-world scenarios.  

3. **🌐 Transliteration and Translation with Encoder-Decoder Models**  
   - An **Encoder-Decoder model** equipped with an attention mechanism ensures smooth transliteration and translation of the extracted text.  
   - Supports multiple regional languages, transforming local scripts into easily readable and understandable formats.  

4. **📊 Model Evaluation and Performance**  
   - **YOLOv5** achieved an impressive **mAP of 0.72** during text detection.  
   - The Encoder-Decoder translation model boasts **89% accuracy**, ensuring reliable and meaningful results.  


## **💡 Why It Matters**  

- **For Travelers** ✈️  
  Navigate foreign regions with ease, understanding signboards in real time.  

- **For Inclusivity** 🌍  
  Break language barriers, making public spaces accessible to all.  

- **For Innovation** 🚀  
  Showcases the power of AI in solving real-world problems with a blend of Computer Vision, NLP, and Machine Learning.  


## **📈 Features**  
- Real-time **Text Detection** and **Localization**.  
- Accurate **Text Extraction** from regional scripts.  
- Multi-language **Transliteration and Translation**.  
- High-performance models with optimized accuracy and efficiency.  


## **🚀 Technologies Used**  

### **Core Technologies**  
- **YOLOv5**: For fast and accurate text detection.  
- **OCR Tools**: For precise text extraction from detected regions.  
- **Encoder-Decoder Model with Attention**: For efficient transliteration and translation.  

### **Programming & Frameworks**  
- **Python** 🐍: The backbone for implementing machine learning pipelines.  
- **TensorFlow/PyTorch** 🔥: For training and deploying the ML models.  
- **OpenCV** 📷: For image preprocessing and visualization.  


## **📊 Results**  
- **Text Detection**: Achieved a **mean Average Precision (mAP)** of **0.72**.  
- **Translation Accuracy**: Reached an impressive **89%**, ensuring reliable communication.  


## **🌏 Impact**  
This project is a step toward a world where languages no longer stand in the way of exploration, accessibility, and communication. **Signboard Translation from Vernacular Languages** is more than just a project – it’s a leap into a future where everyone can connect and navigate with ease.  

Welcome to the future of language-bridging technology! 🚀🖥️  

