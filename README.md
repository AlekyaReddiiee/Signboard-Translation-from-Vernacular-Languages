# **Signboard Translation from Vernacular Languages** ğŸŒâœ¨  

![image](https://github.com/user-attachments/assets/06b70652-772e-4e2d-afec-517e6e172ee7)


### **Breaking Language Barriers with AI**  

Imagine navigating through unfamiliar streets where signboards speak a language you donâ€™t understand. ğŸš Thatâ€™s where **Signboard Translation from Vernacular Languages** steps in, combining cutting-edge technology to break linguistic barriers and make navigation seamless for everyone.  

## **ğŸŒŸ What Itâ€™s All About**  
This project leverages the power of **Machine Learning** ğŸ¤–, **Computer Vision** ğŸ–¼ï¸, and **Natural Language Processing (NLP)** ğŸŒ to translate text from signboards written in regional or vernacular languages into a desired language, such as English. Itâ€™s an intelligent system that doesnâ€™t just read signboards â€“ it **understands** them.  


## **ğŸ”§ The Tech Behind the Magic**  

1. **ğŸ” Text Detection with YOLOv5**  
   - Using **YOLOv5**, the project precisely detects text regions in images, even in complex or noisy environments.  
   - Ensures fast and accurate localization, laying the groundwork for the translation pipeline.  

2. **ğŸ“œ Text Extraction with OCR**  
   - Text from the detected regions is extracted using advanced **Optical Character Recognition (OCR)** tools.  
   - Handles clear and faded text with remarkable precision, making it ideal for real-world scenarios.  

3. **ğŸŒ Transliteration and Translation with Encoder-Decoder Models**  
   - An **Encoder-Decoder model** equipped with an attention mechanism ensures smooth transliteration and translation of the extracted text.  
   - Supports multiple regional languages, transforming local scripts into easily readable and understandable formats.  

4. **ğŸ“Š Model Evaluation and Performance**  
   - **YOLOv5** achieved an impressive **mAP of 0.72** during text detection.  
   - The Encoder-Decoder translation model boasts **89% accuracy**, ensuring reliable and meaningful results.  


## **ğŸ’¡ Why It Matters**  

- **For Travelers** âœˆï¸  
  Navigate foreign regions with ease, understanding signboards in real time.  

- **For Inclusivity** ğŸŒ  
  Break language barriers, making public spaces accessible to all.  

- **For Innovation** ğŸš€  
  Showcases the power of AI in solving real-world problems with a blend of Computer Vision, NLP, and Machine Learning.  


## **ğŸ“ˆ Features**  
- Real-time **Text Detection** and **Localization**.  
- Accurate **Text Extraction** from regional scripts.  
- Multi-language **Transliteration and Translation**.  
- High-performance models with optimized accuracy and efficiency.  


## **ğŸš€ Technologies Used**  

### **Core Technologies**  
- **YOLOv5**: For fast and accurate text detection.  
- **OCR Tools**: For precise text extraction from detected regions.  
- **Encoder-Decoder Model with Attention**: For efficient transliteration and translation.  

### **Programming & Frameworks**  
- **Python** ğŸ: The backbone for implementing machine learning pipelines.  
- **TensorFlow/PyTorch** ğŸ”¥: For training and deploying the ML models.  
- **OpenCV** ğŸ“·: For image preprocessing and visualization.  


## **ğŸ“Š Results**  
- **Text Detection**: Achieved a **mean Average Precision (mAP)** of **0.72**.  
- **Translation Accuracy**: Reached an impressive **89%**, ensuring reliable communication.  


## **ğŸŒ Impact**  
This project is a step toward a world where languages no longer stand in the way of exploration, accessibility, and communication. **Signboard Translation from Vernacular Languages** is more than just a project â€“ itâ€™s a leap into a future where everyone can connect and navigate with ease.  

Welcome to the future of language-bridging technology! ğŸš€ğŸ–¥ï¸  

